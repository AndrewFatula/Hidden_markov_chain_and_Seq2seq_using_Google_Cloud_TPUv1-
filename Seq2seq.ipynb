{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Seq2seq.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN+O7Q0etYwG3g1R7BORaLG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AndrewFatula/Hidden_markov_chain_and_Seq2seq_using_Google_Cloud_TPUv1-/blob/master/Seq2seq.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HlkoGCLQ0Ahe",
        "colab_type": "code",
        "outputId": "cb863a74-78e0-4f57-921f-b9f8060f4965",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "import numpy as np\n",
        "import string\n",
        "import os\n",
        "import sys\n",
        "import time\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "import tensorflow as tf\n",
        "from collections import Counter\n",
        "from matplotlib import pyplot as plt\n",
        "from nltk.translate import bleu_score\n",
        "from keras import regularizers\n",
        "from copy import deepcopy as dc\n",
        "import tensorboardcolab as tb\n",
        "print(tf.__version__)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.0.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tJ1_citv8gLk",
        "colab_type": "text"
      },
      "source": [
        "Importing all needed packages."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "On17B68F0E17",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install --upgrade auth\n",
        "!pip uninstall grpcio\n",
        "!pip uninstall tensorflow\n",
        "!pip install grpcio==1.24.3\n",
        "!pip install tensorflow==2.0.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mGBhGW7W8ciG",
        "colab_type": "text"
      },
      "source": [
        "Default version of tensorflow in colab is 1.15, so in order to gain all the benefits of tensorflow 2.0, current version of tensorflow needs to be uninstalled and then we can install the 2.0 version, but in order to use google cloud TPU v1 with tensorflow 2.0 before installing 2.0 version of tensorflow packages like grpcio and auth should be reinstalled the same way to versions specified above in code.\n",
        "\n",
        "When given packages are reinstalled runtime have to be reset in order to activates updates."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0DCCb17s0GH0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wq0z-8NO8plk",
        "colab_type": "text"
      },
      "source": [
        "Importing all needed tools and authentificating in google account in order to import data in colab."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3JHVzWcF0Hr1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "downloaded = drive.CreateFile({'id':'1Z7odQLtZ7RmWERaRDJHDvbX_3VJ2ptvu'}) # all phrases in movies\n",
        "downloaded.GetContentFile('movie_lines.txt') \n",
        "downloaded = drive.CreateFile({'id':'1TdbFyBvMGV_N8iszqTIAb7V1Vx_eSdMr'}) # all conversations in movies\n",
        "downloaded.GetContentFile('movie_conversations.txt') \n",
        "downloaded = drive.CreateFile({'id':'1YTQeB3x_HTeEA5sjrleJD3notEKaPBnM'}) # all titles of movies\n",
        "downloaded.GetContentFile('movie_titles_metadata.txt')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NW-JqRfE8oxU",
        "colab_type": "text"
      },
      "source": [
        "Loading all needed datafiles for constucting training dataset including GLOVE 50-demensional pretrained vector representations for 400000 English words trained on data from Twitter - which is needed in training seq2seq model to check phrases similarity"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TUZknwlN0JA_",
        "colab_type": "code",
        "outputId": "d9c4343c-008a-436e-be95-4a7f0e8e42fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 763
        }
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "if 'COLAB_TPU_ADDR' not in os.environ:\n",
        "  print('ERROR: Not connected to a TPU runtime; please see the first cell in this notebook for instructions!')\n",
        "else:\n",
        "  tpu_address = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
        "  print ('TPU address iis', tpu_address)\n",
        "\n",
        "\n",
        "cluster_resolver = tf.distribute.cluster_resolver.TPUClusterResolver(\n",
        "    tpu=tpu_address)\n",
        "tf.config.experimental_connect_to_cluster(cluster_resolver)\n",
        "tf.tpu.experimental.initialize_tpu_system(cluster_resolver)\n",
        "tpu_strategy = tf.distribute.experimental.TPUStrategy(cluster_resolver)\n",
        "\n",
        "print ('Number of devices: {}'.format(tpu_strategy.num_replicas_in_sync))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TPU address iis grpc://10.33.193.226:8470\n",
            "INFO:tensorflow:Initializing the TPU system: 10.33.193.226:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: 10.33.193.226:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Number of devices: 8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cGfNg7sR8z_V",
        "colab_type": "text"
      },
      "source": [
        "Setting up TPU v1 hardware acceleration system. \n",
        "Definig TPU cluster_resolver and tpu_distributed_strategy for training seq2seq."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wwM0dzb40Kc4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "SEPARATOR = \"+++$+++\"\n",
        "MAX_TOKENS_X = 12\n",
        "MAX_TOKENS_Y = 10\n",
        "MAX_TOKENS_CONV = 50\n",
        "MIN_TOKEN_FREQ = 3\n",
        "\n",
        "VEC_SIZE = 50\n",
        "\n",
        "EMB_FILE = 'glove.6B.50d.txt'\n",
        "GENRES = \"horror,thriller,war\"\n",
        "WITH_EXCEPTION = True\n",
        "\n",
        "\n",
        "def tokenize(str_):\n",
        "\treturn TweetTokenizer(preserve_case=False).tokenize(str_)\n",
        "\n",
        "\n",
        "def remove_all(str, substrings):\n",
        "\tindex = 0\n",
        "\tfor substr in substrings:\n",
        "\t\tlength = len(substr)\n",
        "\t\twhile str.find(substr) != -1:\n",
        "\t\t\tindex = str.find(str)\n",
        "\t\t\tstr = str[0 : index] + str[index + length:]\n",
        "\treturn str\n",
        "\n",
        "\n",
        "\n",
        "def load_movies(genres, exception = False):\n",
        "\n",
        "\t'''This function loads all the movie titles of specicfied genres \n",
        "\t\tfrom <movie_titles_metadata.txt> file and returns list of movie titles'''\n",
        "\n",
        "\n",
        "\tmovies = []\n",
        "\twith open(\"movie_titles_metadata.txt\", 'rb') as gf:\n",
        "\n",
        "\t\tfor line in gf:\n",
        "\t\t\tline = str(line, encoding='utf-8', errors='ignore')\n",
        "\t\t\tarr_line = list(map( lambda x: x.strip(), line.split(SEPARATOR) ))\n",
        "\t\t\tline_genres = list(map( lambda x: x.strip(\" '\"), arr_line[-1].strip(\"[]\").split(\",\") ))\n",
        "\t\t\tappend = True\n",
        "   \n",
        "\t\t\tfor genre in genres:\n",
        "\t\t\t\tif not exception:\n",
        "\t\t\t\t\tappend = False\n",
        "\t\t\t\t\tif genre in line_genres:\n",
        "\t\t\t\t\t\tappend = True\n",
        "\t\t\t\t\t\tbreak\n",
        "\t\t\t\telse:\n",
        "\t\t\t\t\tif genre in line_genres:\n",
        "\t\t\t\t\t\tappend = False\n",
        "\t\t\t\t\t\tbreak\n",
        "\n",
        "\t\t\tif append:\n",
        "\t\t\t\tmovies.append(arr_line[0])\n",
        "\t\t\t\t\n",
        "\n",
        "\treturn movies\t\t\t\t\n",
        "\n",
        "\n",
        "def read_phrases(movies = [], genres = []):\n",
        "\n",
        "\t''' This function loads all phrasses from <movie_lines.txt> file which are \n",
        "\t\t\tsaid in given movie list as an argument of this function\n",
        "\t\t\tIf function is called with no argument than it reads phrasses \n",
        "\t\t\tfrom all the movies available in dataset  '''\n",
        "\n",
        "\tphrases = {}\n",
        "\n",
        "\twith open('movie_lines.txt', 'rb') as lf:\n",
        "\n",
        "\t\tfor line in lf:\n",
        "\t\t\tline = str(line, encoding='utf-8', errors='ignore').replace(\"<u>\",\"\").replace(\"</u>\",\"\")\n",
        "\n",
        "\t\t\tarr_line = list(map( lambda x: x.strip(), line.split(SEPARATOR) ))\n",
        "\t\t\t#phrases are loaded in dictionary, the key is index of a conversation\n",
        "\t\t\t\n",
        "\t\t\tif not movies:\n",
        "\t\t\t\tphrases[arr_line[0]] = tokenize(remove_all(arr_line[-1],\n",
        "\t\t\t\t                                           [\"<b>\",\"</b>\",\"<u>\",\"</u>\",\"<i>\",\"</i>\",\"<u>\", \"</u>\"]))\n",
        "\t\t\telif arr_line[2] in movies: \n",
        "\t\t\t\tphrases[arr_line[0]] = tokenize(remove_all(arr_line[-1],\n",
        "\t\t\t\t                                           [\"<b>\",\"</b>\",\"<u>\",\"</u>\",\"<i>\",\"</i>\",\"<u>\", \"</u>\"]))\n",
        "\t\n",
        "\t\n",
        "\treturn phrases\t\n",
        "\t\n",
        "\n",
        "\n",
        "def read_dialogues(phrases, movies):\n",
        "\n",
        "\t''' this function constructs dialogs from phrases in the movies,\n",
        "\t\t\tall the needed information for dialogs construction is \n",
        "\t\t\treaded from file <movie_conversations.txt>'''\n",
        "\n",
        "\tdialogues = []\n",
        "\twith open(\"movie_conversations.txt\", 'rb') as df:\n",
        "\n",
        "\t\tfor line in df:\t\n",
        "\t\t\tline = str(line, encoding='utf-8', errors='ignore')\n",
        "\t\t\tarr_line = list(map( lambda x: x.strip(), line.split(SEPARATOR) ))\n",
        "\t\t\tdialog = list(map( lambda x: x.strip(\"' \"), arr_line[-1].strip(\"[]\").split(\",\") ))\n",
        "\n",
        "\t\t\tif not movies:\n",
        "\t\t\t\tdialogues.append([phrases[phrase] for phrase in dialog])\n",
        "\t\t\telif arr_line[2] in movies:\t\n",
        "\t\t\t\tdialogues.append([phrases[phrase] for phrase in dialog])\n",
        "\n",
        "\treturn dialogues\t\t\t\t\n",
        "\n",
        "\n",
        "def get_phrase_pairs(genres = None, max_tokins = MAX_TOKENS_X, n_pairs = None, exception = False):\n",
        "\n",
        "\t''' This function constructs phrase_pairs dataset where each instance of \n",
        "\t\tdataset is phrase and response to that phrase '''\n",
        "\n",
        "\t#when genres in not specified it read phrses from all the movies is available\n",
        "\tif genres == None:\n",
        "\t\tall_phrases = read_phrases()\n",
        "\t\tmovies = []\n",
        "\telse:\n",
        "\t\tmovies = load_movies(genres, exception = exception)\n",
        "\t\tall_phrases = read_phrases(movies, genres = genres)\t\n",
        "\t\n",
        "\t#before constructing phrase pairs dataset we need to get conversations \n",
        "\t#dataset from all readed phrases\n",
        "\tconversations = read_dialogues(all_phrases, movies)\n",
        "\tphrase_pairs = []\n",
        "\n",
        "\tfor conv in conversations:\n",
        "\t\tprev_phrase = None\n",
        "\n",
        "\t\tbiggest_len = 0\n",
        "\t\tfor phrase in conv:\n",
        "\t\t\tif len(phrase) > biggest_len:\n",
        "\t\t\t\tbiggest_len = len(phrase)\n",
        "\t\n",
        "\t\tif biggest_len > MAX_TOKENS_CONV:\n",
        "\t\t\tcontinue\n",
        "\n",
        "\t\tfor phrase in conv:\n",
        "\t\t\tif prev_phrase is not None :\n",
        "\t\t\t\tphrase_pairs.append((prev_phrase, phrase))\n",
        "\t\t\tprev_phrase = phrase\n",
        "\n",
        "\tif not len(genres) == 0:\n",
        "\t\tif not exception:\n",
        "\t\t\tprint(\"Total number of loaded phrases in \" + \",\".join(genres) + \" movies is :\", len(phrase_pairs))\n",
        "\t\telse:\n",
        "\t\t\tprint(\"Total number of loaded phrases not in \" + \",\".join(genres) + \" movies is :\", len(phrase_pairs))\t\t\n",
        "\telse:\n",
        "\t\tprint(\"Total number of loaded phrases of all movies : \" ,len(phrase_pairs))\n",
        "\n",
        "\tif (n_pairs == None) or (n_pairs >= len(phrase_pairs)) :\n",
        "\t\treturn phrase_pairs, conversations\n",
        "\telse:\n",
        "\t\tnp.random.shuffle(phrase_pairs)\n",
        "\t\treturn phrase_pairs[0:n_pairs], conversations\n",
        "\n",
        "\t\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t1jhJxpq9Izw",
        "colab_type": "text"
      },
      "source": [
        "Fuctions above are used to construct phrase_pairs dataset from movies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yAj1fKDE0MGP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def word_corrector(word):\n",
        "\n",
        "\t''' this function is used to convert commonly used english words shortcuts \n",
        "\t\tto corresponding them full forms '''\n",
        "\n",
        "\tdots = ['. ..', '. . .', '..', '. ...','...  ...', '.  ...', '. .']\n",
        "\tcomonly_used = [\"that\", \"what\", \"there\", \"who\", \"where\", \"how\"]\n",
        "\tpronouns = [\"it\", \"she\", \"he\"]\n",
        "\n",
        "\tif word[-3:] == \"'ll\":\n",
        "\t\tdecoded = [ word[:-3] , \"will\" ]\n",
        "\t\treturn decoded\n",
        "\n",
        "\telif word[-2:] == \"'d\":\n",
        "\t\tdecoded = [ word[:-2] , \"would\" ]\n",
        "\t\treturn decoded \n",
        "\n",
        "\telif word[-2:] == \"'s\" or word[-2:] == \"s'\": \n",
        "\t\tif not word[:-2] in comonly_used+pronouns:\n",
        "\t\t\tdecoded =  [ \"someone\" , \"'\" , \"s\" ]\n",
        "\t\telse:\n",
        "\t\t\tdecoded = [word]\n",
        "\t\treturn decoded\n",
        "\n",
        "\telif word[-2:] == \"'t\":\n",
        "\t\t\n",
        "\t\tif word == \"can't\":\n",
        "\t\t\tdecoded = [ \"can\" , \"not\" ]\n",
        "\t\telif word == \"won't\":\n",
        "\t\t\tdecoded = [ \"will\" , \"not\" ]\n",
        "\t\telse:\n",
        "\t\t\tdecoded = [ word[:-3] , \"not\" ]\t\n",
        "\t\treturn decoded   \n",
        "\n",
        "\telif word[-3:] == \"'re\":\n",
        "\t\tdecoded = [ word[:-3] , \"are\" ]\n",
        "\t\treturn decoded \n",
        "\n",
        "\telif word == \"i'm\":\n",
        "\t\tdecoded = [ \"i\", \"am\" ]\n",
        "\t\treturn decoded \n",
        "\n",
        "\telif word[-3:] == \"'ve\":\n",
        "\t\tdecoded = [ word[:-3] , \"have\" ]\n",
        "\t\treturn decoded \n",
        "\n",
        "\telif word[:2] == \"y'\":\n",
        "\t\tdecoded = [ \"you\" , word[2:] ]\n",
        "\t\treturn decoded\n",
        "\n",
        "\telif word[:2] == \"dont\":\n",
        "\t\tdecoded = [ \"do\" , \"not\" ]\n",
        "\t\treturn decoded\n",
        "\telse:\n",
        "\t\tif word in dots:\n",
        "\t\t\tword = \"...\"\n",
        "\t\telif word == \"u\":\n",
        "\t\t\tword = \"you\"\n",
        "\t\telif word == \"ur\":\n",
        "\t\t\tword = \"your\"\t\n",
        "\n",
        "\t\treturn [word]\n",
        "\n",
        "####### \n",
        "def get_word_dict2(phrase_pairs):\n",
        "\n",
        "\t''' this function constructs token dictionary with words which is available\n",
        "\t\t in embeddings dictionary retrieved from GLOVE 50-dimensional wordvectors representations,\n",
        "\t\t\tand is present in phrase_pairs dataset with frequency >= than specified MIN_TOKEN_FREQ '''\n",
        "\n",
        "\tfreq_count = Counter()\n",
        "\tsizes_x = []\n",
        "\tsizes_y = []\n",
        "\n",
        "\tfor pair in phrase_pairs:\n",
        "\t\tif len(pair[0]) < MAX_TOKENS_X + 1 and len(pair[1]) < MAX_TOKENS_Y + 1:\n",
        "\t\t\tfreq_count.update(pair[0])\n",
        "\t\t\tfreq_count.update(pair[1])\n",
        "\n",
        "\tword_set = list(map(lambda x: '+' + x[0] if x[1] >= MIN_TOKEN_FREQ else '-' + x[0], freq_count.items() ))\n",
        "\tword_dict = {\"EMPTY\":0, \"BEGIN\":1, \"END\" : 2}\n",
        "\ti = 3\n",
        "\tn=0\n",
        "\tfor word in word_set:\n",
        "\t\tif word[0] == \"+\":\n",
        "\t\t\tn+=1\n",
        "\t\t\tcorrect_word = word_corrector(word[1:])\n",
        "   \n",
        "\t\t\tfor corrected in correct_word:\n",
        "\t\t\t\tif not corrected in word_dict.keys() :\n",
        "\t\t\t\t\tword_dict[corrected] = i\n",
        "\t\t\t\t\ti+=1\n",
        "\treturn word_dict\n",
        "\n",
        "\n",
        "\n",
        "def convert_phrases2(phrase_pairs, word_dict):\n",
        "\n",
        "\t''' this function converts all the words in phrases dataset to tokens \n",
        "\t\tbased on token dictionary retrieved from embeddings file and phrase_pairs dataset,\n",
        "\t\t\tphrases with words which frequencies are < MIN_TOKEN_FREQ or with words which \n",
        "\t\t\tare unavailable in words embeddings file are ignored,\n",
        "\t\t\talso it converts common words shortcuts in phrases to corresponding them full forms, \n",
        "\t\t\tit returns converted to tokens phrase_pairs separately and lengths for each phrase in pair '''\n",
        "\n",
        "\tsizes_x = []\n",
        "\tsizes_y = []\n",
        "\tconverted_x = []\n",
        "\tconverted_y = []\n",
        "\tconverted_x_reverse = []\n",
        "\n",
        "\tfor pair in phrase_pairs:\n",
        "\t\tif len(pair[0]) < MAX_TOKENS_X + 1 and len(pair[1]) < MAX_TOKENS_Y + 1:\n",
        "\t\t\tphrase1 = []\n",
        "\t\t\tphrase2 = []\n",
        "\t\t\tphrase1_reverse = []\n",
        "\t\t\tfor word in pair[0]:\n",
        "\t\t\t\tcorrect_word = word_corrector(word)\n",
        "\n",
        "\t\t\t\tfor correct in correct_word:\n",
        "\t\t\t\t\tif correct in word_dict.keys():\n",
        "\t\t\t\t\t\tphrase1.append(word_dict[correct])\n",
        "\t\t\t\t\telse:\n",
        "\t\t\t\t\t\tphrase1.append(word_dict[\"EMPTY\"])\n",
        "\n",
        "\t\t\tfor word in pair[1]:\n",
        "\t\t\t\tcorrect_word = word_corrector(word)\n",
        "\n",
        "\t\t\t\tfor correct in correct_word:\n",
        "\t\t\t\t\tif correct in word_dict.keys():\n",
        "\t\t\t\t\t\tphrase2.append(word_dict[correct])\n",
        "\t\t\t\t\telse:\n",
        "\t\t\t\t\t\tphrase2.append(word_dict[\"EMPTY\"])\n",
        "\n",
        "\t\t\tphrase1 = [1] + phrase1 + [2]\n",
        "\t\t\tphrase2 = [1] + phrase2 + [2]\n",
        "\t\t\n",
        "\t\t\tif not word_dict[\"EMPTY\"] in phrase1[1:] and not word_dict[\"EMPTY\"] in phrase2[1:] and \\\n",
        "\t\t\t\t (not (len(phrase1) > MAX_TOKENS_X + 8 or len(phrase2) > MAX_TOKENS_Y + 8)):\n",
        "\t\t\t\tl1 = len(phrase1)\n",
        "\t\t\t\tfor token_idx in range(l1):\n",
        "\t\t\t\t\tphrase1_reverse.append(phrase1[l1-token_idx-1])\n",
        "\t \n",
        "\t\t\t\tconverted_x.append(phrase1)\n",
        "\t\t\t\tconverted_y.append(phrase2)\n",
        "\t\t\t\tconverted_x_reverse.append(phrase1_reverse)\n",
        "\n",
        "\t\t\t\tsizes_x.append(len(phrase1))\n",
        "\t\t\t\tsizes_y.append(len(phrase2))\n",
        "\t\n",
        "\tlength = len(sizes_x)\n",
        "\tsizes_x = np.array(sizes_x)\n",
        "\tsizes_y = np.array(sizes_y)\n",
        "\n",
        "\treturn converted_x, converted_y, converted_x_reverse, sizes_x.astype(np.int32), sizes_y.astype(np.int32)\n",
        "\n",
        "def calc_bleu_score(out, target):\n",
        "\tsf = bleu_score.SmoothingFunction()\n",
        "\treturn bleu_score.sentence_bleu(target, out, smoothing_function=sf.method1, weights=(0.5, 0.5))\n",
        "\n",
        "\n",
        "def get_words_from_tokens(sentence, token_dict):\n",
        "\treturn [token_dict[value] for value in sentence]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\t"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s4B3MZuD9NCO",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "functions above are used to prepare and preprocces phrase_pairs dataset for training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AZVOuTMl0Nkz",
        "colab_type": "code",
        "outputId": "39abf9a0-0fee-4361-d304-cb7264d8474e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "\n",
        "\n",
        "print(\"constructing vectorspace for pharse pairs dataset...\")\n",
        "\n",
        "phrase_pairs, dialogues = get_phrase_pairs(genres = GENRES.split(\",\"), exception = WITH_EXCEPTION)\n",
        "phrase_pairs = make_addition(phrase_pairs)\n",
        "word_dict = get_word_dict2(phrase_pairs)\n",
        "\n",
        "\n",
        "phrase_number = len(phrase_pairs)\n",
        "inverse_word_dict = {}\n",
        "\n",
        "for key in word_dict.keys():\n",
        "  inverse_word_dict[word_dict[key]] = key\n",
        "\n",
        "inverse_emb_dict = {}\n",
        "\n",
        "\n",
        "print(\"phrases are loaded\")\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "constructing vectorspace for pharse pairs dataset...\n",
            "Total number of loaded phrases not in horror,thriller,war movies is : 101717\n",
            "phrases are loaded\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iZ8fWUuq9XtH",
        "colab_type": "text"
      },
      "source": [
        "Code above reads and filters phrase pairs for training dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2UWZfYUz0PDW",
        "colab_type": "code",
        "outputId": "b620f896-783a-42c4-a689-5632fa4831f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "source": [
        "print(\"preparing and preprocces dataset...\")\n",
        "\n",
        "converted_x, converted_y, converted_x_reverse, true_lengths_x, true_lengths_y = convert_phrases2(phrase_pairs, word_dict)\n",
        "\n",
        "width_x = int(max(true_lengths_x))\n",
        "width_y = int(max(true_lengths_y))\n",
        "\n",
        "sparse_x = np.zeros((len(true_lengths_x), width_x))\n",
        "sparse_y = np.zeros((len(true_lengths_x), width_y))\n",
        "sparse_x_reverse = np.zeros((len(true_lengths_x), width_x))\n",
        "semi_hot_y = np.zeros((len(true_lengths_x), width_y))\n",
        "\n",
        "\n",
        "#padding each sequence in x_data and y_data\n",
        "for i in range(len(true_lengths_x)):\n",
        "    sparse_x[i, : true_lengths_x[i]] = np.array(converted_x[i])\n",
        "    sparse_y[i, : true_lengths_y[i]] = np.array(converted_y[i])\n",
        "    sparse_x_reverse[i, : true_lengths_x[i]] = np.array(converted_x_reverse[i])\n",
        "    semi_hot_y[i, : true_lengths_y[i]] = np.ones((true_lengths_y[i]))\n",
        "\n",
        "#semi_hot_y is needed to mask not needed losses of empty elements in sequence\n",
        "\n",
        "length = len(true_lengths_x)\n",
        "\n",
        "#lengths_x_one_hot is needed to mask hidden states retrieved from empty part of x sequence\n",
        "lengths_x_onehot = tf.one_hot(np.array(true_lengths_x) - 1, width_x)\n",
        "\n",
        "# and now we need to get rid of extra words in word_dict after we filtered phrase_pairs by lengths and unknown words \n",
        "# and convert phrases without extra tokens corresponding to those words\n",
        "unique_tokens = np.unique(np.concatenate((np.unique(sparse_x), np.unique(sparse_y)), axis = 0))\n",
        "transfer_tokens = {}\n",
        "transfer_dict = {}\n",
        "\n",
        "for key in word_dict.keys():\n",
        "    inverse_word_dict[word_dict[key]] = key\n",
        "\n",
        "\n",
        "for i in range(len(unique_tokens)):\n",
        "    transfer_tokens[unique_tokens[i]] = i\n",
        "    transfer_dict[inverse_word_dict[unique_tokens[i]]] = i\n",
        "\n",
        "inverse_word_dict = {}\n",
        "\n",
        "for key in transfer_dict.keys():\n",
        "    inverse_word_dict[transfer_dict[key]] = key\n",
        "\n",
        "word_dict = transfer_dict\n",
        "\n",
        "for i in range(length):\n",
        "    for j in range(width_x):\n",
        "        sparse_x[i,j] = transfer_tokens[sparse_x[i,j]]\n",
        "        sparse_x_reverse[i,j] = transfer_tokens[sparse_x_reverse[i,j]]\n",
        "\n",
        "    for k in range(width_y):\n",
        "        sparse_y[i,k] = transfer_tokens[sparse_y[i,k]]\n",
        "\n",
        "sparse_x = tf.convert_to_tensor(sparse_x, dtype = tf.int32)  \n",
        "sparse_y = tf.convert_to_tensor(sparse_y, dtype = tf.int32) \n",
        "sparse_x_reverse = tf.convert_to_tensor(sparse_x_reverse, dtype = tf.int32)  \n",
        "semi_hot_y = tf.convert_to_tensor(semi_hot_y, dtype = tf.int32)\n",
        "\n",
        "dict_size = len(list(word_dict.values()))    \n",
        "\n",
        "\n",
        "print(\"original dict_size:\", dict_size)\n",
        "print(\"number of phrase_pairs:\", length)\n",
        "print(\"min word frequency:\", MIN_TOKEN_FREQ)\n",
        "print(\"max phrase1 length:\", MAX_TOKENS_X)\n",
        "print(\"max phrase2 length:\", MAX_TOKENS_Y)\n",
        "print(\"data is ready\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "preparing and preprocces dataset...\n",
            "original dict_size: 6271\n",
            "number of phrase_pairs: 33538\n",
            "min word frequency: 3\n",
            "max phrase1 length: 12\n",
            "max phrase2 length: 10\n",
            "data is ready\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wPi2NCNy2oq0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "weights = []\n",
        "weights.append(seq2seq.emb_layer.get_weights())\n",
        "weights.append(seq2seq.decoder.get_weights())\n",
        "weights.append(seq2seq.encoder.get_weights())\n",
        "weights.append(seq2seq.interpreter.get_weights())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CkbZbjfF9gc6",
        "colab_type": "text"
      },
      "source": [
        "As well as TPU v1 can be executed only with static computational graph, recurrent layers have to be unrolled to train on TPU, as it needs to be unrolled all the training data must have fixed shape. \n",
        "\n",
        "In order to train seq2seq model with variable size input sequences, lenghts of train instances are encoded as one_hot for x_sequence vectors and semi_hot vectors for y_sequence (semi_hot means vector of ones of sequence lengths and zeroes for the rest).\n",
        "\n",
        "This vectors are multiplied with network output during training so non-zero gradient for each sequence will have variable lengths as training sequences and rest of the gradients will be zero.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7BqQEsqP0Qkl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with tpu_strategy.scope():\n",
        "\n",
        "\n",
        "    class Seq2Seq(tf.keras.Model):\n",
        "\n",
        "        ''' inherited from tf.keras.model class simle seq2seq model class with one embedding layer, 2 recurrent layers and two dense layers  '''\n",
        "\n",
        "        def __init__(   self, hidden_size, emb_size, \n",
        "                        word_dict, inverse_word_dict ):\n",
        "\n",
        "            super(Seq2Seq, self).__init__()\n",
        "            self.dict_size = len(word_dict)\n",
        "            self.hidden_size = hidden_size\n",
        "            self.emb_size = emb_size\n",
        "            self.word_dict = word_dict\n",
        "            self.inverse_word_dict = inverse_word_dict\n",
        "\n",
        "            self.emb_layer = tf.keras.layers.Embedding(self.dict_size, emb_size)\n",
        "\n",
        "            self.decoder = tf.keras.layers.LSTM( units = hidden_size, recurrent_activation = \"sigmoid\",\n",
        "                                                kernel_regularizer=regularizers.l2(0.003),\n",
        "                                                recurrent_regularizer=regularizers.l2(0.003), \n",
        "                                                bias_regularizer=regularizers.l2(0.003),\n",
        "                                                dropout = 0.05, recurrent_dropout = 0,\n",
        "                                                return_state = True, return_sequences = True, \n",
        "                                                unroll = True )\n",
        "            \n",
        "            self.encoder = tf.keras.layers.LSTM( units = hidden_size, recurrent_activation = \"sigmoid\",\n",
        "                                               kernel_regularizer=regularizers.l2(0.003), \n",
        "                                               recurrent_regularizer=regularizers.l2(0.003),\n",
        "                                               bias_regularizer=regularizers.l2(0.003),\n",
        "                                                dropout = 0, recurrent_dropout = 0, \n",
        "                                               return_state = True, unroll = True )\n",
        "            \n",
        "            self.encoder_reverse = tf.keras.layers.GRU( units = hidden_size, recurrent_activation = \"sigmoid\", \n",
        "                                                       kernel_regularizer=regularizers.l2(0.003), \n",
        "                                                       recurrent_regularizer=regularizers.l2(0.003), \n",
        "                                                       bias_regularizer=regularizers.l2(0.003),\n",
        "                                                        dropout = 0, recurrent_dropout = 0, \n",
        "                                                       return_state = True, unroll = True )\n",
        "            \n",
        "            self.interpreter = tf.keras.Sequential([ tf.keras.layers.Dense(self.dict_size) ])\n",
        "            self.end_words = [\".\"]\n",
        "\n",
        "\n",
        "        def get_words(self, tokens):\n",
        "\n",
        "            '''fucntion that returns words from output tokens'''\n",
        "\n",
        "            words = []\n",
        "            prev_token = None\n",
        "            for token in tokens:\n",
        "                if token != prev_token:\n",
        "                    words.append(self.inverse_word_dict[token])\n",
        "                    prev_token = token\n",
        "                    \n",
        "            return words\n",
        "\n",
        "\n",
        "\n",
        "        def encode_sequence(self, x_batch, x_batch_reverse, one_hot_x, seq_len, train):\n",
        "\n",
        "            ''' encode sequence method, that returns hidden state for encoder for each input x_sequence'''\n",
        "\n",
        "            batch_size = np.shape(x_batch)[0]\n",
        "            hidden_total = tf.zeros([batch_size, self.hidden_size])\n",
        "            hidden_state = tf.zeros([batch_size, self.hidden_size])\n",
        "            hidden_total_reverse = tf.zeros([batch_size, self.hidden_size])\n",
        "            hidden_state_reverse = tf.zeros([batch_size, self.hidden_size])\n",
        "            for i in range(seq_len):\n",
        "                _ , hidden_state, hidden_state_reverse = self.encoder(x_batch[:,i:i+1], [hidden_state, hidden_state_reverse], training = train)\n",
        "                hidden_total += one_hot_x[:,i,None] * hidden_state\n",
        "                hidden_total_reverse += one_hot_x[:,i,None] * hidden_state_reverse\n",
        "            return [hidden_total, hidden_total_reverse]\n",
        "\n",
        "\n",
        "        def decode_sequence(self, hidden, y_batch, train ):\n",
        "\n",
        "            ''' method for training seq2seq with teacher \n",
        "                witch takes as argument encoded hidden state from x_input sequence\n",
        "            '''\n",
        "\n",
        "            output, _, _ = self.decoder(y_batch, hidden, training = train)\n",
        "            return self.interpreter(output)\n",
        "\n",
        "\n",
        "        def decode_chain_sequence_argmax(self, hidden, seq_len, train):\n",
        "\n",
        "            ''' method for training seq2seq without teacher \n",
        "                that takes as argument encoded hidden state and generates output as a chain sequence\n",
        "            '''\n",
        "\n",
        "            total_output = []\n",
        "            batch_size = np.shape(hidden[0])[0]\n",
        "            current_emb =  self.emb_layer(tf.ones((batch_size, 1)))\n",
        "\n",
        "            for i in range(seq_len):\n",
        "                output, hidden_h, hidden_c = self.decoder(current_emb, hidden, training = train)\n",
        "                hidden = [hidden_h, hidden_c]\n",
        "                current_distribution = self.interpreter(output)\n",
        "                total_output.append(current_distribution)\n",
        "                current_word = tf.argmax(current_distribution, axis=-1)\n",
        "                current_emb = self.emb_layer(current_word)\n",
        "\n",
        "            return tf.concat(total_output, axis = 1)\n",
        "\n",
        "\n",
        "        def decode_chain_sequence_sample(self, hidden, seq_len, train):\n",
        "\n",
        "            ''' method for training seq2seq without teacher \n",
        "                that takes as argument encoded hidden state and generates output as a chain sequence\n",
        "            '''\n",
        "\n",
        "            total_output = []\n",
        "            batch_size = np.shape(hidden[0])[0]\n",
        "            current_emb =  self.emb_layer(tf.ones((batch_size, 1)))\n",
        "            sampled_tokens = []\n",
        "\n",
        "            for i in range(seq_len):\n",
        "                output, hidden_h, hidden_c = self.decoder(current_emb, hidden, training = train)\n",
        "                hidden = [hidden_h, hidden_c]\n",
        "                current_distribution = self.interpreter(output)\n",
        "                total_output.append(current_distribution)\n",
        "                current_word = tf.random.categorical(current_distribution[:,0,:], 1)\n",
        "                sampled_tokens.append(current_word)\n",
        "                current_emb = self.emb_layer(current_word)\n",
        "\n",
        "            return tf.concat(total_output, axis = 1), tf.concat(sampled_tokens, axis = 1)\n",
        "\n",
        "\n",
        "        def call(self, input_x, input_x_reverse, input_y, one_hot_x, train = True):\n",
        "\n",
        "            ''' forward method for training with teacher'''\n",
        "\n",
        "            seq_len_x = np.shape(input_x)[1]\n",
        "            input_x_reverse = self.emb_layer(input_x_reverse)\n",
        "            input_x = self.emb_layer(input_x)\n",
        "            input_y = self.emb_layer(input_y)\n",
        "            hidden = self.encode_sequence(input_x, input_x_reverse, one_hot_x, seq_len_x, train)\n",
        "            predictions = self.decode_sequence(hidden, input_y, train)\n",
        "            return predictions\n",
        "\n",
        "\n",
        "        def call_2(self, input_x, input_x_reverse, one_hot_x, seq_len_y, train = True):\n",
        "\n",
        "            ''' forward method for training without teacher'''\n",
        "\n",
        "            seq_len_x = np.shape(input_x)[1]\n",
        "            input_x_reverse = self.emb_layer(input_x_reverse)\n",
        "            input_x = self.emb_layer(input_x)\n",
        "            hidden = self.encode_sequence(input_x, input_x_reverse, one_hot_x, seq_len_x, train)\n",
        "            predictions = self.decode_chain_sequence_argmax(hidden, seq_len_y, train)\n",
        "            return predictions\n",
        "\n",
        "\n",
        "        def call_sample(self, input_x, input_x_reverse, one_hot_x, seq_len_y, train = True):\n",
        "\n",
        "            ''' forward method for training without teacher'''\n",
        "\n",
        "            seq_len_x = np.shape(input_x)[1]\n",
        "            input_x_reverse = self.emb_layer(input_x_reverse)\n",
        "            input_x = self.emb_layer(input_x)\n",
        "            hidden = self.encode_sequence(input_x, input_x_reverse, one_hot_x, seq_len_x, train)\n",
        "            predictions, sampled_tokens = self.decode_chain_sequence_sample(hidden, seq_len_y, train)\n",
        "            return predictions, sampled_tokens\n",
        "\n",
        "\n",
        "\n",
        "        def save(self):\n",
        "            weights = []\n",
        "            weights.append(self.emb_layer.get_weights())\n",
        "            weights.append(self.decoder.get_weights())\n",
        "            weights.append(self.encoder.get_weights())\n",
        "            for layer in self.interpreter.layers:\n",
        "                weights.append(layer.get_weights())\n",
        "            return weights\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        def decode_chain_sequence_test(self, hidden, r = 0, sampling = False):\n",
        "\n",
        "            ''' method applied to trained seq2seq that generate output sequence for each input phrase ''' \n",
        "\n",
        "            current_emb =  self.emb_layer(tf.ones((1, 1)))\n",
        "            total_output = []\n",
        "\n",
        "            if r > 0:\n",
        "                current_emb += tf.convert_to_tensor(np.random.rand(1, self.emb_size), dtype = tf.float32) * 0.1 * r\n",
        "\n",
        "            for _ in range(15):\n",
        "                output, hidden_h, hidden_c = self.decoder(current_emb, hidden, training = False)\n",
        "                hidden = [hidden_h, hidden_c]\n",
        "                current_distribution = self.interpreter(output)\n",
        "                if sampling:\n",
        "                    current_word = tf.random.categorical(current_distribution[0,:,:], 1)\n",
        "                else:\n",
        "                    current_word = tf.argmax(current_distribution, axis = -1 )\n",
        "                if (self.inverse_word_dict[current_word.numpy()[0,0]] == \"END\" ) or \\\n",
        "                    (self.inverse_word_dict[current_word.numpy()[0,0]] == \"EMPTY\"):\n",
        "                    if len(total_output) < 1:\n",
        "                        return self.decode_chain_sequence_test(hidden, r+1)\n",
        "                    else:\n",
        "                        return total_output\n",
        "\n",
        "                total_output.append(current_word.numpy()[0,0])  \n",
        "                current_emb = self.emb_layer(current_word)\n",
        "                r = 0\n",
        "\n",
        "            return total_output  \n",
        "\n",
        "\n",
        "        def encode_sequence_test(self, x, x_reverse):\n",
        "\n",
        "            ''' method applied to trained seq2seq model, returns hidden state for each input sequence'''\n",
        "\n",
        "            _ , hidden, hidden_reverse = self.encoder(x[None, :, :], training = False )\n",
        "            return [hidden, hidden_reverse]  \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        def predict(self, phrase, sampling = False):\n",
        "\n",
        "            ''' method applied on trained seq2seq that returns output phrase on each input phrase'''\n",
        "            \n",
        "            phrase_tokens = []\n",
        "\n",
        "            for word in phrase:\n",
        "                if word in self.word_dict.keys():\n",
        "                    phrase_tokens.append(self.word_dict[word])\n",
        "\n",
        "            phrase_tokens = phrase_tokens\n",
        "            phrase_tokens_reverse = [phrase_tokens[len(phrase_tokens)-1-i] for i in range(len(phrase_tokens))]\n",
        "\n",
        "            inputs = []\n",
        "            inputs_reverse = []\n",
        "\n",
        "            for word in phrase_tokens:\n",
        "                inputs.append(self.emb_layer(word))\n",
        "            \n",
        "            for word in phrase_tokens_reverse:\n",
        "                inputs_reverse.append(self.emb_layer(word))\n",
        "\n",
        "            inputs = tf.convert_to_tensor(inputs, dtype = tf.float32)\n",
        "            inputs_reverse = tf.convert_to_tensor(inputs_reverse, dtype = tf.float32)\n",
        "            hidden = self.encode_sequence_test(inputs, inputs_reverse)\n",
        "            output = self.decode_chain_sequence_test(hidden, sampling = sampling)\n",
        "            output_words = self.get_words(output)\n",
        "\n",
        "            return output_words\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mFaWVdbO9wpS",
        "colab_type": "text"
      },
      "source": [
        "In code above class of seq2seq model for training is subclassed from tf.keras.model class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "22NeQkmr0SSL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "with tpu_strategy.scope():\n",
        "\n",
        "    def ngramm_recall_score( predictions, labels,\n",
        "                                semi_hot_y,\n",
        "                                seq_len,\n",
        "                                weights = tf.convert_to_tensor([1.,1.,1.,1.]) ):\n",
        "        \n",
        "        max_seq_len = np.shape(labels)[1]\n",
        "        batch_size = np.shape(labels)[0]\n",
        "        lengths = tf.where(tf.equal(predictions, 2), 1., 0.) * \\\n",
        "                            tf.range(0, max_seq_len, dtype = tf.float32)[None, :]\n",
        "        lengths  += tf.cast(tf.where(tf.equal(predictions, 2), \n",
        "                                     0., max_seq_len), dtype = tf.float32)\n",
        "        lengths = tf.reduce_min(lengths, axis = 1)\n",
        "        semihot_predictions = tf.ones((batch_size, max_seq_len), dtype = tf.float32) * \\\n",
        "                                        tf.range(0, max_seq_len, dtype = tf.float32)[None, :]\n",
        "        semihot_predictions = tf.where(semihot_predictions <= lengths[:, None], 1., 0.)\n",
        "        predictions = tf.cast(predictions, tf.int32)\n",
        "        labels = tf.cast(labels, tf.int32)\n",
        "\n",
        "        n1_gramms = 0\n",
        "        for token_idx in range(max_seq_len):\n",
        "            n1_gramms += tf.math.sign( tf.reduce_sum( tf.where(tf.equal(labels[ :, token_idx : token_idx + 1], \n",
        "                                                                        predictions), 1., 0.) * \\\n",
        "                                                     semi_hot_y[ :, token_idx : token_idx + 1] * \\\n",
        "                                                     semihot_predictions , axis = 1) )\n",
        "        n1_gramms /= seq_len\n",
        "            \n",
        "        n2_gramms = 0\n",
        "        for token_idx in range(max_seq_len-1):\n",
        "            n2_gramms += tf.math.sign( tf.reduce_sum( tf.where(tf.equal(labels[ :, token_idx : token_idx + 1], predictions[:,:-1]), 1., 0.) * \\\n",
        "                                                     semi_hot_y[:, token_idx : token_idx + 1] * \\\n",
        "                                                      tf.where(tf.equal(labels[ :, token_idx + 1 : token_idx + 2], predictions[:,1:]), 1., 0.) * \\\n",
        "                                                      semi_hot_y[:, token_idx + 1 : token_idx + 2] *\\\n",
        "                                                      semihot_predictions[:,1:] , axis = 1) )\n",
        "        n2_gramms /= tf.maximum((seq_len - 1.), 1.)\n",
        "\n",
        "        n3_gramms = 0\n",
        "        for token_idx in range(max_seq_len-2):\n",
        "            n3_gramms += tf.math.sign( tf.reduce_sum( tf.where( tf.equal(labels[ :, token_idx : token_idx + 1], \n",
        "                                                                        predictions[:,:-2]), 1., 0. ) * \\\n",
        "                                                    semi_hot_y[ :, token_idx : token_idx + 1] * \\\n",
        "                                                      tf.where( tf.equal(labels[ :, token_idx + 1 : token_idx + 2], \n",
        "                                                                        predictions[:,1:-1]), 1., 0. ) * \\\n",
        "                                                     semi_hot_y[ :, token_idx + 1 : token_idx + 2] * \\\n",
        "                                                      tf.where( tf.equal(labels[ :, token_idx + 2 : token_idx + 3],\n",
        "                                                                        predictions[:,2:]), 1., 0. ) * \\\n",
        "                                                     semi_hot_y[ :, token_idx + 2 : token_idx + 3]  * \\\n",
        "                                                      semihot_predictions[:,2:] , axis = 1) )      \n",
        "        n3_gramms /= tf.maximum((seq_len - 2.), 1.)\n",
        "\n",
        "        n4_gramms = 0\n",
        "        for token_idx in range(max_seq_len-3):\n",
        "            n4_gramms += tf.math.sign( tf.reduce_sum( tf.where(tf.equal(labels[ :, token_idx : token_idx + 1],\n",
        "                                                                        predictions[:,:-3]), 1., 0.) * \\\n",
        "                                                     semi_hot_y[ :, token_idx : token_idx + 1] * \\\n",
        "                                                      tf.where(tf.equal(labels[ :, token_idx + 1 : token_idx + 2], \n",
        "                                                                        predictions[:,1:-2]), 1., 0.) * \\\n",
        "                                                     semi_hot_y[ :, token_idx + 1 : token_idx + 2] * \\\n",
        "                                                      tf.where(tf.equal(labels[ :, token_idx + 2 : token_idx + 3], \n",
        "                                                                        predictions[:,2:-1]), 1., 0.) * \\\n",
        "                                                     semi_hot_y[ :, token_idx + 2 : token_idx + 3] * \\\n",
        "                                                      tf.where(tf.equal(labels[ :, token_idx + 3 : token_idx + 4], \n",
        "                                                                        predictions[:,3:]), 1., 0.) * \\\n",
        "                                                      semi_hot_y[ :, token_idx + 3 : token_idx + 4] * \\\n",
        "                                                      semihot_predictions[:,3:] , axis = 1) )\n",
        "        n4_gramms /= tf.maximum((seq_len - 3.), 1.)\n",
        "\n",
        "        labels_lengths = tf.reduce_sum(semi_hot_y, axis = 1)\n",
        "        predictions_lengths = tf.reduce_sum(semihot_predictions, axis = 1)\n",
        "        len_diff = tf.where(labels_lengths < predictions_lengths, predictions_lengths - labels_lengths, 0)\n",
        "\n",
        "        recall_penalty = 1 / (1.5/(1.5+tf.math.exp(-len_diff/2)))\n",
        "        recall_penalty /= tf.reduce_max(recall_penalty)\n",
        "\n",
        "        n_gramms = tf.stack([n1_gramms, n2_gramms, n3_gramms, n4_gramms], axis = 1)\n",
        "        weights /=tf.reduce_sum(weights)\n",
        "\n",
        "        return tf.reduce_sum(n_gramms*weights[None,:], axis = 1)*recall_penalty\n",
        "        \n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JDieqCgc-tpp",
        "colab_type": "text"
      },
      "source": [
        "One of the most eficcient metrics to evaluate similarity between two sentences is Bleu score ot Bilingual evaluation understudy score, with calculates modified precision of two sencences based of n_gramms precision, in code above is implemented function which calculates BLEU score for multiple sentences in parallel."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JKw4vhGf0T2h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "with tpu_strategy.scope():\n",
        "\n",
        "\n",
        "\tdef get_argmax_recall(labels, predictions, semi_hot_y, seq_lens):\n",
        "\n",
        "\t\tpredictions_argmax = tf.stop_gradient(tf.argmax(predictions, axis = -1))\n",
        "  \n",
        "\t\targmax_recall = ngramm_recall_score( predictions_argmax, labels,\n",
        "\t\t\t\t\t\t\t\t\t\t\tsemi_hot_y,\n",
        "\t\t\t\t\t\t\t\t\t\t\tseq_lens )\n",
        "  \n",
        "\t\treturn tf.nn.compute_average_loss(argmax_recall, global_batch_size=BATCH_SIZE)\n",
        "\n",
        "\n",
        "\n",
        "\tdef compute_loss1(labels, predictions, \n",
        "\t\t\t\t\t\tsemi_hot_y):\n",
        "\n",
        "\t\t''' cross_entropy_loss function for distributed strategy'''\n",
        "\n",
        "\t\tper_example_loss = loss_object(labels, predictions)*semi_hot_y\n",
        "\t\treturn tf.nn.compute_average_loss(per_example_loss , global_batch_size=BATCH_SIZE)\n",
        "\n",
        "\n",
        "\n",
        "\tdef compute_loss2(labels, predictions_probabilities_argmax, predictions_probabilities_sample,\n",
        "\t\t\t\t\t\tsampled_tokens,\n",
        "\t\t\t\t\t\tsemi_hot_y,\n",
        "\t\t\t\t\t\tseq_lens):\n",
        "\n",
        "\t\t'''log_probability loss for correcting output probalility distribution for distributed strategy'''\n",
        "\n",
        "\t\tprobabilities_no_grad = tf.stop_gradient(predictions_probabilities_argmax)\n",
        "\t\targmax_tokens = tf.stop_gradient(tf.cast(tf.argmax(probabilities_no_grad, axis = -1), tf.float32))\n",
        "\t\tsampled_tokens = tf.stop_gradient(tf.cast(sampled_tokens, tf.float32))\n",
        "  \n",
        "\t\tlabels = tf.cast(labels, tf.float32)\n",
        "\t\tbatch_size = np.shape(labels)[0]\n",
        "\t\tmax_seq_len = np.shape(labels)[1]\n",
        "\t\tsemihot_sampled = []\n",
        "\t\tsample_recall = []\n",
        "        \n",
        "\t\tfor idx in range(np.shape(sampled_tokens)[0]):\n",
        "\t\t\t\n",
        "\t\t\tsampled_lengths = tf.where(tf.equal(sampled_tokens[idx, :, :], 2), 1., 0.) * \\\n",
        "\t\t\t\t\t\t\t\ttf.range(0, max_seq_len, dtype = tf.float32)[None, :]\n",
        "\n",
        "\t\t\tsampled_lengths  += tf.cast(tf.where(tf.equal(sampled_tokens[idx, :, :], 2),\n",
        "\t\t\t                                     0., max_seq_len), dtype = tf.float32)\n",
        "   \n",
        "\t\t\tsampled_lengths = tf.reduce_min(sampled_lengths, axis = 1)\n",
        "\t\t\tsemihot_sampled_ = tf.ones((batch_size, max_seq_len), dtype = tf.float32) * \\\n",
        "\t\t\t\t\t\t\t\ttf.range(0, max_seq_len, dtype = tf.float32)[None, :]\n",
        "\n",
        "\t\t\tsemihot_sampled.append(tf.where(semihot_sampled_ <= sampled_lengths[:, None], 1., 0.))\n",
        "\t\t\tsample_recall.append(ngramm_recall_score( sampled_tokens[idx, :, :], labels,\n",
        "                                \t\t\t\t\t\tsemi_hot_y,\n",
        "                                \t\t\t\t\t\tseq_lens ))\n",
        "  \n",
        "\t\targmax_recall = ngramm_recall_score( argmax_tokens, labels,\n",
        "                                \t\t\t\t\t\tsemi_hot_y,\n",
        "                                \t\t\t\t\t\tseq_lens )\n",
        "\t\tlog_probabilities_corrector = []\n",
        "\t\tfor idx in range(np.shape(sampled_tokens)[0]):\n",
        "\t\t\trecall_corrector = tf.where( argmax_recall < 0.97, sample_recall[idx] - argmax_recall , 0. )\n",
        "   \n",
        "\t\t\tgathered_sample_probabilities = tf.gather_nd( - tf.nn.log_softmax(predictions_probabilities_sample[idx,:,:],\n",
        "\t\t\t                                            \t\t\t\t\t\taxis = -1) , \n",
        "\t\t\t                                            tf.cast(sampled_tokens[idx,:,:], tf.int32)[:,:,None],\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\t        batch_dims = 2)\n",
        "   \n",
        "\t\t\tlog_probabilities_corrector.append(gathered_sample_probabilities  * \\\n",
        "\t\t\t                                   recall_corrector[:, None] * \\\n",
        "\t\t\t\t\t\t\t\t\t\t\t    semihot_sampled[idx] )\n",
        "   \n",
        "\t\tlog_probabilities_corrector = tf.concat(log_probabilities_corrector, axis = 0)\n",
        "\t\tsample_recall = tf.concat(sample_recall, axis = 0)\n",
        "\t\treturn tf.nn.compute_average_loss(log_probabilities_corrector, \n",
        "\t\t                                  global_batch_size=BATCH_SIZE*np.shape(sampled_tokens)[0]),  \\\n",
        "               tf.nn.compute_average_loss(sample_recall, global_batch_size=BATCH_SIZE*np.shape(sampled_tokens)[0]), \\\n",
        "               tf.nn.compute_average_loss(argmax_recall, global_batch_size=BATCH_SIZE)\n",
        "\n",
        "\n",
        "\n",
        "\t### For each training method corresponding distributed training step function needs to be constructed \n",
        "\n",
        "\tdef distributed_train_step1(dataset_inputs):\n",
        "\n",
        "\t\t''' function that applies distriuted TPU strategy to train_step1 function'''\n",
        "\n",
        "\t\tper_replica_losses = tpu_strategy.experimental_run_v2(train_step1,\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\targs=(dataset_inputs,))\n",
        "\t\treturn tpu_strategy.reduce(tf.distribute.ReduceOp.SUM, per_replica_losses,\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\taxis=None)\n",
        "\n",
        "\tdef distributed_train_step2(dataset_inputs):\n",
        "\n",
        "\t\t''' function that applies distriuted TPU strategy to train_step2 function'''\n",
        "\n",
        "\t\tper_replica_losses = tpu_strategy.experimental_run_v2(train_step2,\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\targs=(dataset_inputs,))\n",
        "\t\treturn tpu_strategy.reduce(tf.distribute.ReduceOp.SUM, per_replica_losses,\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\taxis=None)\n",
        "\n",
        "\tdef distributed_correction(dataset_inputs):\n",
        "\n",
        "\t\t''' function that applies distriuted TPU strategy to train_step3 function'''\n",
        "\n",
        "\t\tper_replica_losses = tpu_strategy.experimental_run_v2(dist_correction,\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\targs=(dataset_inputs,))\n",
        "\t\treturn tpu_strategy.reduce(tf.distribute.ReduceOp.SUM, per_replica_losses,\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\taxis=None)\n",
        "\n",
        "\n",
        "\t@tf.function\n",
        "\tdef train_step1(inputs):\n",
        "\n",
        "\t\t''' train_step1 fuction for crossentropy teacher training method \n",
        "\t\t\twith @tf.function decorator that assures construction of static computation graph for training\n",
        "\t\t\tfunction returns crosscntropy_loss regardless wich loss was \n",
        "\t\t\tapplied at training step in order to track loss value during training loop\n",
        "\t\t'''\n",
        "\t\tinput_x = inputs[0]\n",
        "\t\tinput_x_reverse = inputs[1]\n",
        "\t\tinput_y = inputs[2]\n",
        "\t\tone_hot_x = inputs[3]\n",
        "\t\tsemi_hot_y = tf.cast(inputs[4], tf.float32)\n",
        "\t\twith tf.GradientTape() as tape:\n",
        "\t\t\tpredictions = seq2seq(input_x, input_x_reverse, input_y[:,:-1], one_hot_x)\n",
        "\t\t\tloss = compute_loss1(input_y[:,1:], predictions, semi_hot_y[:,1:])\n",
        "\t\tgradients = tape.gradient(loss, seq2seq.trainable_variables)\n",
        "\t\toptimizer1.apply_gradients(zip(gradients, seq2seq.trainable_variables))\n",
        "\t\treturn loss\n",
        "\n",
        "\n",
        "\t@tf.function\n",
        "\tdef train_step2(inputs):\n",
        "\n",
        "\t\t''' train_step2 fuction for crossentropy chain_sequence training method \n",
        "\t\t'''\n",
        "\t\tinput_x = inputs[0]\n",
        "\t\tinput_x_reverse = inputs[1]\n",
        "\t\tinput_y = inputs[2]\n",
        "\t\tone_hot_x = inputs[3]\n",
        "\t\tsemi_hot_y = tf.cast(inputs[4], tf.float32)\n",
        "\t\tseq_lens = tf.reduce_sum(semi_hot_y[:,1:], axis = 1)\n",
        "\t\twith tf.GradientTape() as tape:\n",
        "\t\t\tpredictions = seq2seq.call_2(input_x, input_x_reverse, one_hot_x, np.shape(input_y)[1]-1)\n",
        "\t\t\tloss = compute_loss1(input_y[:,1:], predictions, semi_hot_y[:,1:])\n",
        "\t\t\targmax_recall = get_argmax_recall(input_y[:,1:], predictions, semi_hot_y[:,1:], seq_lens)\n",
        "\t\tgradients = tape.gradient(loss, seq2seq.trainable_variables)\n",
        "\t\toptimizer2.apply_gradients(zip(gradients, seq2seq.trainable_variables))\n",
        "\n",
        "\t\ttrain_accuracy(input_y[:,1:], tf.keras.activations.softmax(predictions, axis = -1) *\n",
        "\t\t\t\t\tsemi_hot_y[:,1:,None] + (1-semi_hot_y)[:,1:,None ] * \\\n",
        "\t\t\t\t\ttf.one_hot(0,seq2seq.dict_size)[None, None,:]) \n",
        "  \t\t# in order to get correct accuracy we need to mask padded values\n",
        "\n",
        "\t\treturn tf.stack([loss, argmax_recall])\n",
        "\n",
        "\t@tf.function\n",
        "\tdef dist_correction(inputs):\n",
        "\n",
        "\t\t''' dist_correction fuction performs output distribution correction based on word2wec \n",
        "\t\t'''\n",
        "\n",
        "\t\tinput_x = inputs[0]\n",
        "\t\tinput_x_reverse = inputs[1]\n",
        "\t\tinput_y = inputs[2]\n",
        "\t\tone_hot_x = inputs[3]\n",
        "\t\tsemi_hot_y = tf.cast(inputs[4], tf.float32)\n",
        "\t\tseq_lens = tf.reduce_sum(semi_hot_y[:,1:], axis = 1)\n",
        "\t\tpredictions_sample = []\n",
        "\t\tsampled_tokens = []\n",
        "\t\twith tf.GradientTape() as tape:\n",
        "\t\t\tpredictions_argmax = seq2seq.call_2(input_x, input_x_reverse, \n",
        "\t\t\t                                    one_hot_x, np.shape(input_y)[1]-1, train = False)\n",
        "\t\t\tfor _ in range(15):\n",
        "\t\t\t\tsampled_values = seq2seq.call_sample(input_x, input_x_reverse, \n",
        "\t\t\t\t                                     one_hot_x, np.shape(input_y)[1]-1, train = False)\n",
        "\t\t\t\tpredictions_sample.append(sampled_values[0])\n",
        "\t\t\t\tsampled_tokens.append(sampled_values[1])\n",
        "\t\t\tpredictions_sample = tf.stack(predictions_sample, axis = 0)\n",
        "\t\t\tsampled_tokens = tf.stack(sampled_tokens, axis = 0)\n",
        "\t\t\tloss, sample_recall, argmax_recall = compute_loss2(input_y[:,1:], \n",
        "\t\t\t                                    predictions_argmax, predictions_sample, sampled_tokens, semi_hot_y[:,1:], seq_lens)\n",
        "\t\t\tprint_loss = tf.stop_gradient(compute_loss1(input_y[:,1:], predictions_argmax, semi_hot_y[:,1:]))\n",
        "\t\tgradients = tape.gradient(loss, seq2seq.trainable_variables, )\n",
        "\t\toptimizer3.apply_gradients(zip(gradients, seq2seq.trainable_variables))\n",
        "  \n",
        "\t\ttrain_accuracy(input_y[:,1:], tf.keras.activations.softmax(predictions_argmax, axis = -1) *\n",
        "\t\t                 semi_hot_y[:,1:,None] + (1-semi_hot_y)[:,1:,None] * \n",
        "\t\t\t\t\t\t           tf.one_hot(0,seq2seq.dict_size)[None, None,:]) \n",
        "  \t\t# in order to get correct accuracy we need to mask padded values\n",
        "\n",
        "\t\treturn tf.stack([print_loss, sample_recall, argmax_recall], axis = 0)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VCODAm1dAZgg",
        "colab_type": "text"
      },
      "source": [
        "Above are defined 3 different loss function for training seq2seq model:\n",
        "  1. cross_entropy los function for teacher training method\n",
        "  2. cross_entropy loss function for chain training method\n",
        "  2. probability correction loss function for correcting output probability distribution over, this loss function is applied to sampled sequence rather than argmax and is baed on calculating recall score between labels and sampled sentence"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vpKMVV_40Vvd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " with tpu_strategy.scope():\n",
        "\n",
        "    def crossentropy_training_loop( train_dist_dataset, \n",
        "                                    teacher_prob,\n",
        "                                    mean_pre_loss, argmax_recals ):\n",
        "\n",
        "        ''' training function for crossentropy training loop\n",
        "        '''\n",
        "\n",
        "        for x in train_dist_dataset:\n",
        "            if np.random.rand() < teacher_prob:\n",
        "                loss = distributed_train_step1(x)\n",
        "            else:\n",
        "                track_values = distributed_train_step2(x)\n",
        "                loss2 = track_values[0]\n",
        "                argmax_recal = track_values[1]\n",
        "                mean_pre_loss.append(loss2)\n",
        "                argmax_recals.append(argmax_recal)\n",
        "        \n",
        "            if teacher_prob == 1:\n",
        "                mean_pre_loss.append(loss)\n",
        "\n",
        "\n",
        "    def correction_training_loop( train_dist_dataset, \n",
        "                                    teacher_prob,\n",
        "                                    mean_pre_loss, mean_sample_bleu, mean_argmax_bleu ):\n",
        "\n",
        "        ''' training function for crossentropy training loop\n",
        "        '''\n",
        "\n",
        "        for x in train_dist_dataset:\n",
        "\n",
        "\n",
        "            track_values = distributed_correction(x)\n",
        "            loss = track_values[0]\n",
        "            sample_bleu = track_values[1]\n",
        "            argmax_bleu = track_values[2]\n",
        "\n",
        "            mean_pre_loss.append(loss)\n",
        "            mean_sample_bleu.append(sample_bleu)\n",
        "            mean_argmax_bleu.append(argmax_bleu)\n",
        "\n",
        "\n",
        "                \n",
        "\n",
        "\n",
        "\n",
        "\t\t\t"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6VX3cIvQBczc",
        "colab_type": "text"
      },
      "source": [
        "Training circle functions for cross_entropy training method and probability correction is defined in code above"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXR7oFz00YZb",
        "colab_type": "code",
        "outputId": "493a299a-fc22-459f-9631-21ccecddd192",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "EMBEDDING_SIZE = 128\n",
        "HIDDEN_SIZE = 1024\n",
        "BATCH_SIZE = 2048\n",
        "\n",
        "\n",
        "\n",
        "tf.get_logger().setLevel('ERROR')\n",
        "tf.autograph.set_verbosity(1)\n",
        "\n",
        "with tpu_strategy.scope():\n",
        "\n",
        "\tdef relu(x):\n",
        "\t\tif x < 0:\n",
        "\t\t\treturn 0\n",
        "\t\telse:\n",
        "\t\t\treturn x\n",
        "\n",
        "\n",
        "\t\n",
        "\t#instanciating seq2seq model from seq2seq class\n",
        "\t#seq2seq = Seq2Seq( HIDDEN_SIZE, EMBEDDING_SIZE,\n",
        "\t#\t\t\t\t   word_dict, inverse_word_dict )\n",
        "\n",
        "\t\n",
        "\ttrain_length = np.shape(sparse_x)[0]\n",
        "\ttrain_steps = int(train_length/BATCH_SIZE)\n",
        "\n",
        "\t#defining tf_callbacks and evaluation metrices\n",
        "\ttrain_accuracy = tf.keras.metrics.SparseCategoricalAccuracy('train_accuracy')\n",
        "\tnull_train_acc = np.mean(np.sum(1-semi_hot_y, axis = 1)-1)/np.shape(sparse_y)[1]\n",
        "\n",
        "\ttrain_losses = []\n",
        "\ttrain_accuracies = []\n",
        "\tteacher_method_losses=[]\n",
        "\n",
        "\ttrain_correction_accuracies = []\n",
        "\tcorrection_sample_recall = []\n",
        "\tcorrection_argmax_recall = []\n",
        "\t\n",
        "\n",
        "\tLEARNING_RATE = tf.keras.optimizers.schedules.ExponentialDecay(0.0005, decay_steps = train_steps, decay_rate = 0.985, staircase= True)\n",
        "\tLEARNING_RATE2 = tf.keras.optimizers.schedules.ExponentialDecay(7e-5, decay_steps = train_steps*4, decay_rate = 1.1, staircase= True)    \n",
        "\n",
        "\tloss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits = True, reduction=tf.keras.losses.Reduction.NONE)\n",
        "\n",
        "\toptimizer1 = tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE)\n",
        "\toptimizer2 = tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE)\n",
        "\toptimizer3 = tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE2)\n",
        "\toptimizer4 = tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE2)\n",
        "\n",
        "\tn_epochs = 79\n",
        "\tis_cross_entropy = True\n",
        "\tteacher_prob = 0\n",
        "\tprint(\"crossentropy training ... \")\n",
        "\tfor epoch in range(n_epochs):\n",
        "\t\tepoch_start = time.localtime(time.time())\n",
        "\t\t\n",
        "\t\tmean_pre_loss = [0]\n",
        "\t\tmean_sample_recall = []\n",
        "\t\tmean_argmax_recall = []\n",
        "\n",
        "\t\t# in order to make training independent from instances order in batches, \n",
        "\t\t#distributed training dataset have to be shuffled and reconstructed every epoch during training\n",
        "\t\tdataset = tf.data.Dataset.from_tensor_slices((sparse_x, sparse_x_reverse, \n",
        "\t\t                                              sparse_y, lengths_x_onehot,\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t    semi_hot_y)).shuffle(150000).batch(BATCH_SIZE, drop_remainder = True) \n",
        "\t\t\t\t \n",
        "\t\ttrain_dist_dataset = tpu_strategy.experimental_distribute_dataset(dataset)\n",
        "  \n",
        "\t\tif epoch == 590:\n",
        "\t\t\tprint(\"distribution correction training...\")\n",
        "\t\t\tteacher_prob = 0\n",
        "\t\t\tis_cross_entropy = False\n",
        "\n",
        "\t\tif(epoch + 1) % 40 == 0 and is_cross_entropy:\n",
        "\t\t\tteacher_prob = 1 - teacher_prob\n",
        "\n",
        "\t\tif is_cross_entropy:    \n",
        "\n",
        "\t\t\tcrossentropy_training_loop( train_dist_dataset, \n",
        "\t\t\t\t\t\t\t\t\t\tteacher_prob, \n",
        "\t\t\t\t\t\t\t\t\t\tmean_pre_loss, mean_argmax_recall)\n",
        "\t\telse:\n",
        "\n",
        "\t\t\tcorrection_training_loop( train_dist_dataset, \n",
        "\t\t\t\t\t\t\t\t\t\tteacher_prob, \n",
        "\t\t\t\t\t\t\t\t\t\tmean_pre_loss, mean_sample_recall, mean_argmax_recall)\n",
        "\n",
        "\t\tepoch_end = time.localtime(time.time())\n",
        "\t\tstart_in_sec = epoch_start[3]*3600 + epoch_start[4]*60 + epoch_start[5]\n",
        "\t\tend_in_sec = epoch_end[3]*3600 + epoch_end[4]*60 + epoch_end[5]\n",
        "\t\tepoch_time = end_in_sec - start_in_sec\n",
        "\n",
        "\t\ttrain_loss = np.mean(mean_pre_loss)\n",
        "\t\ttrain_acc = relu((train_accuracy.result().numpy()-null_train_acc)/(1-null_train_acc))\n",
        "\t\ttrain_accuracy.reset_states()\n",
        "\n",
        "\t\tif is_cross_entropy:\n",
        "\t\t\tif not teacher_prob == 1:\n",
        "\t\t\t\targmax_recall = np.mean(mean_argmax_recall)\n",
        "\t\t\t\tcorrection_argmax_recall.append(argmax_recall)\n",
        "\t\t\t\ttrain_losses.append(train_loss)\n",
        "\t\t\t\ttrain_accuracies.append(train_acc)\n",
        "\t\n",
        "\t\t\t\tprint(\"Epoch: \", epoch,\", Train loss:\", train_loss, \n",
        "\t\t\t\t      \", Train accuracy:\", train_acc, \n",
        "\t\t\t\t\t     \", argmax_recall_score:\", argmax_recall, \n",
        "\t\t\t\t\t\t    \", teacher_prob:\", teacher_prob,\", time: \", \n",
        "\t\t\t\t\t\t\t   epoch_time ,\" sec \")\n",
        "\n",
        "\t\t\telse:\n",
        "\t\t\t\tteacher_method_losses.append(train_loss)\n",
        "\t\t\t\tprint(\"Epoch: \", epoch,\", Train loss:\",\n",
        "\t\t\t\t      train_loss, \", Train accuracy:\",\n",
        "\t\t\t\t\t     train_acc, \", teacher_prob:\", \n",
        "\t\t\t\t\t\t    teacher_prob,\", time: \",\n",
        "\t\t\t\t\t\t\t   epoch_time ,\" sec \")\n",
        "\t\n",
        "\t\n",
        "\n",
        "\t\telse:\n",
        "\t\t\tsample_recall = np.mean(mean_sample_recall)\n",
        "\t\t\targmax_recall = np.mean(mean_argmax_recall)\n",
        "\t\t\tprint(\"Epoch: \", epoch,\", Train loss:\",\n",
        "\t\t\t      train_loss, \", Train accuracy:\", \n",
        "\t\t\t\t     train_acc, \", sample_recall_score:\", \n",
        "\t\t\t\t\t    sample_recall, \", argmax_recall_score:\",\n",
        "\t\t\t\t\t\t   argmax_recall, \", time: \",\n",
        "\t\t\t\t\t\t   epoch_time ,\" sec \")\t\n",
        "\n",
        "\t\t\ttrain_correction_accuracies.append(train_acc)\n",
        "\t\t\tcorrection_sample_recall.append(sample_recall)\n",
        "\t\t\tcorrection_argmax_recall.append(argmax_recall)\n",
        "   \n",
        "\n",
        "\t\n",
        "\t\t\t\t\n",
        "\t\t\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "crossentropy training ... \n",
            "Epoch:  0 , Train loss: 4.84873171413646 , Train accuracy: 0.8810123019142041 , argmax_recall_score: 0.80986917 , teacher_prob: 0 , time:  22  sec \n",
            "Epoch:  1 , Train loss: 3.3076862868140724 , Train accuracy: 0.8866508689462183 , argmax_recall_score: 0.8082433 , teacher_prob: 0 , time:  2  sec \n",
            "Epoch:  2 , Train loss: 2.843006035860847 , Train accuracy: 0.8891175003098675 , argmax_recall_score: 0.8061794 , teacher_prob: 0 , time:  2  sec \n",
            "Epoch:  3 , Train loss: 2.6492491609909954 , Train accuracy: 0.890301810436445 , argmax_recall_score: 0.80372894 , teacher_prob: 0 , time:  2  sec \n",
            "Epoch:  4 , Train loss: 2.56414831385893 , Train accuracy: 0.891282474027915 , argmax_recall_score: 0.8039131 , teacher_prob: 0 , time:  3  sec \n",
            "Epoch:  5 , Train loss: 2.523783599629122 , Train accuracy: 0.8920782756263114 , argmax_recall_score: 0.8036523 , teacher_prob: 0 , time:  2  sec \n",
            "Epoch:  6 , Train loss: 2.48529247676625 , Train accuracy: 0.8923422536905392 , argmax_recall_score: 0.80364895 , teacher_prob: 0 , time:  2  sec \n",
            "Epoch:  7 , Train loss: 2.4846361384672275 , Train accuracy: 0.8933568399549762 , argmax_recall_score: 0.8041929 , teacher_prob: 0 , time:  3  sec \n",
            "Epoch:  8 , Train loss: 2.471566775265862 , Train accuracy: 0.8930852375766287 , argmax_recall_score: 0.8036009 , teacher_prob: 0 , time:  2  sec \n",
            "Epoch:  9 , Train loss: 2.466896519941442 , Train accuracy: 0.8932361768967356 , argmax_recall_score: 0.80379313 , teacher_prob: 0 , time:  2  sec \n",
            "Epoch:  10 , Train loss: 2.4542835740482105 , Train accuracy: 0.8932851272033295 , argmax_recall_score: 0.8042046 , teacher_prob: 0 , time:  2  sec \n",
            "Epoch:  11 , Train loss: 2.4471189975738525 , Train accuracy: 0.8935303207255235 , argmax_recall_score: 0.8039016 , teacher_prob: 0 , time:  2  sec \n",
            "Epoch:  12 , Train loss: 2.4480760938981 , Train accuracy: 0.8942468957554597 , argmax_recall_score: 0.80503964 , teacher_prob: 0 , time:  2  sec \n",
            "Epoch:  13 , Train loss: 2.43797565908993 , Train accuracy: 0.894292199650953 , argmax_recall_score: 0.80515635 , teacher_prob: 0 , time:  2  sec \n",
            "Epoch:  14 , Train loss: 2.4301333707921646 , Train accuracy: 0.8948956254394621 , argmax_recall_score: 0.8058622 , teacher_prob: 0 , time:  3  sec \n",
            "Epoch:  15 , Train loss: 2.4401400510002587 , Train accuracy: 0.8944091058007868 , argmax_recall_score: 0.80536914 , teacher_prob: 0 , time:  2  sec \n",
            "Epoch:  16 , Train loss: 2.4382596436668846 , Train accuracy: 0.8943751831278199 , argmax_recall_score: 0.8049978 , teacher_prob: 0 , time:  2  sec \n",
            "Epoch:  17 , Train loss: 2.440976886188283 , Train accuracy: 0.8946391611920478 , argmax_recall_score: 0.8055569 , teacher_prob: 0 , time:  3  sec \n",
            "Epoch:  18 , Train loss: 2.436467128641465 , Train accuracy: 0.8941941885404591 , argmax_recall_score: 0.8044708 , teacher_prob: 0 , time:  2  sec \n",
            "Epoch:  19 , Train loss: 2.441927769604851 , Train accuracy: 0.8942054592656793 , argmax_recall_score: 0.80456024 , teacher_prob: 0 , time:  2  sec \n",
            "Epoch:  20 , Train loss: 2.4229205636417164 , Train accuracy: 0.8947938574205614 , argmax_recall_score: 0.80505294 , teacher_prob: 0 , time:  3  sec \n",
            "Epoch:  21 , Train loss: 2.422266216839061 , Train accuracy: 0.8946844650875411 , argmax_recall_score: 0.80496836 , teacher_prob: 0 , time:  2  sec \n",
            "Epoch:  22 , Train loss: 2.437630428987391 , Train accuracy: 0.8941790504095259 , argmax_recall_score: 0.80485886 , teacher_prob: 0 , time:  2  sec \n",
            "Epoch:  23 , Train loss: 2.4243267283720127 , Train accuracy: 0.8949296586097351 , argmax_recall_score: 0.8055569 , teacher_prob: 0 , time:  2  sec \n",
            "Epoch:  24 , Train loss: 2.4203805642969467 , Train accuracy: 0.8950842443409426 , argmax_recall_score: 0.8052056 , teacher_prob: 0 , time:  2  sec \n",
            "Epoch:  25 , Train loss: 2.425507629618925 , Train accuracy: 0.8946844650875411 , argmax_recall_score: 0.80493224 , teacher_prob: 0 , time:  2  sec \n",
            "Epoch:  26 , Train loss: 2.4128938422483555 , Train accuracy: 0.8952955151901697 , argmax_recall_score: 0.8064635 , teacher_prob: 0 , time:  2  sec \n",
            "Epoch:  27 , Train loss: 2.417136080124799 , Train accuracy: 0.8952275593469298 , argmax_recall_score: 0.80542415 , teacher_prob: 0 , time:  2  sec \n",
            "Epoch:  28 , Train loss: 2.4266039062948788 , Train accuracy: 0.8946957358127613 , argmax_recall_score: 0.80507976 , teacher_prob: 0 , time:  2  sec \n",
            "Epoch:  29 , Train loss: 2.416559093138751 , Train accuracy: 0.8951861228571494 , argmax_recall_score: 0.805789 , teacher_prob: 0 , time:  2  sec \n",
            "Epoch:  30 , Train loss: 2.4146124475142536 , Train accuracy: 0.8950880012493493 , argmax_recall_score: 0.8056773 , teacher_prob: 0 , time:  3  sec \n",
            "Epoch:  31 , Train loss: 2.41915103968452 , Train accuracy: 0.8952878908760501 , argmax_recall_score: 0.805607 , teacher_prob: 0 , time:  2  sec \n",
            "Epoch:  32 , Train loss: 2.4203412112067726 , Train accuracy: 0.8948994928451749 , argmax_recall_score: 0.8059169 , teacher_prob: 0 , time:  2  sec \n",
            "Epoch:  33 , Train loss: 2.4155121270348046 , Train accuracy: 0.8949937470472621 , argmax_recall_score: 0.80515987 , teacher_prob: 0 , time:  3  sec \n",
            "Epoch:  34 , Train loss: 2.4101539920358097 , Train accuracy: 0.895174741634623 , argmax_recall_score: 0.8055772 , teacher_prob: 0 , time:  2  sec \n",
            "Epoch:  35 , Train loss: 2.41395463662989 , Train accuracy: 0.8951936366739629 , argmax_recall_score: 0.806077 , teacher_prob: 0 , time:  2  sec \n",
            "Epoch:  36 , Train loss: 2.4169240839341106 , Train accuracy: 0.8949446862433621 , argmax_recall_score: 0.8054495 , teacher_prob: 0 , time:  3  sec \n",
            "Epoch:  37 , Train loss: 2.411297363393447 , Train accuracy: 0.8955066755420907 , argmax_recall_score: 0.8056067 , teacher_prob: 0 , time:  2  sec \n",
            "Epoch:  38 , Train loss: 2.4143459656659294 , Train accuracy: 0.8950955150661628 , argmax_recall_score: 0.80575716 , teacher_prob: 0 , time:  2  sec \n",
            "Epoch:  39 , Train loss: 1.2350836326094234 , Train accuracy: 0 , teacher_prob: 1 , time:  23  sec \n",
            "Epoch:  40 , Train loss: 0.6690268516540527 , Train accuracy: 0 , teacher_prob: 1 , time:  2  sec \n",
            "Epoch:  41 , Train loss: 0.5779505827847649 , Train accuracy: 0 , teacher_prob: 1 , time:  2  sec \n",
            "Epoch:  42 , Train loss: 0.5565378560739405 , Train accuracy: 0 , teacher_prob: 1 , time:  2  sec \n",
            "Epoch:  43 , Train loss: 0.5475257635116577 , Train accuracy: 0 , teacher_prob: 1 , time:  2  sec \n",
            "Epoch:  44 , Train loss: 0.5449273796642528 , Train accuracy: 0 , teacher_prob: 1 , time:  2  sec \n",
            "Epoch:  45 , Train loss: 0.5400199223967159 , Train accuracy: 0 , teacher_prob: 1 , time:  2  sec \n",
            "Epoch:  46 , Train loss: 0.537040486055262 , Train accuracy: 0 , teacher_prob: 1 , time:  2  sec \n",
            "Epoch:  47 , Train loss: 0.5343402694253361 , Train accuracy: 0 , teacher_prob: 1 , time:  2  sec \n",
            "Epoch:  48 , Train loss: 0.5344734893125647 , Train accuracy: 0 , teacher_prob: 1 , time:  2  sec \n",
            "Epoch:  49 , Train loss: 0.5324600058443406 , Train accuracy: 0 , teacher_prob: 1 , time:  2  sec \n",
            "Epoch:  50 , Train loss: 0.5298215992310468 , Train accuracy: 0 , teacher_prob: 1 , time:  2  sec \n",
            "Epoch:  51 , Train loss: 0.5313674842610079 , Train accuracy: 0 , teacher_prob: 1 , time:  2  sec \n",
            "Epoch:  52 , Train loss: 0.5307899783639347 , Train accuracy: 0 , teacher_prob: 1 , time:  2  sec \n",
            "Epoch:  53 , Train loss: 0.5294689308194553 , Train accuracy: 0 , teacher_prob: 1 , time:  2  sec \n",
            "Epoch:  54 , Train loss: 0.5285747927777907 , Train accuracy: 0 , teacher_prob: 1 , time:  3  sec \n",
            "Epoch:  55 , Train loss: 0.5270841717720032 , Train accuracy: 0 , teacher_prob: 1 , time:  2  sec \n",
            "Epoch:  56 , Train loss: 0.5261983170228846 , Train accuracy: 0 , teacher_prob: 1 , time:  2  sec \n",
            "Epoch:  57 , Train loss: 0.526694646653007 , Train accuracy: 0 , teacher_prob: 1 , time:  2  sec \n",
            "Epoch:  58 , Train loss: 0.5249559002764085 , Train accuracy: 0 , teacher_prob: 1 , time:  2  sec \n",
            "Epoch:  59 , Train loss: 0.5254419095375958 , Train accuracy: 0 , teacher_prob: 1 , time:  2  sec \n",
            "Epoch:  60 , Train loss: 0.5282651992405162 , Train accuracy: 0 , teacher_prob: 1 , time:  2  sec \n",
            "Epoch:  61 , Train loss: 0.5259057037970599 , Train accuracy: 0 , teacher_prob: 1 , time:  2  sec \n",
            "Epoch:  62 , Train loss: 0.5220167777117561 , Train accuracy: 0 , teacher_prob: 1 , time:  2  sec \n",
            "Epoch:  63 , Train loss: 0.5218333356520709 , Train accuracy: 0 , teacher_prob: 1 , time:  2  sec \n",
            "Epoch:  64 , Train loss: 0.5203275259803323 , Train accuracy: 0 , teacher_prob: 1 , time:  2  sec \n",
            "Epoch:  65 , Train loss: 0.519121478585636 , Train accuracy: 0 , teacher_prob: 1 , time:  2  sec \n",
            "Epoch:  66 , Train loss: 0.5204509198665619 , Train accuracy: 0 , teacher_prob: 1 , time:  2  sec \n",
            "Epoch:  67 , Train loss: 0.5203255660393659 , Train accuracy: 0 , teacher_prob: 1 , time:  2  sec \n",
            "Epoch:  68 , Train loss: 0.5206789339289946 , Train accuracy: 0 , teacher_prob: 1 , time:  2  sec \n",
            "Epoch:  69 , Train loss: 0.5183300270753748 , Train accuracy: 0 , teacher_prob: 1 , time:  2  sec \n",
            "Epoch:  70 , Train loss: 0.5185334805180045 , Train accuracy: 0 , teacher_prob: 1 , time:  2  sec \n",
            "Epoch:  71 , Train loss: 0.5189033922027139 , Train accuracy: 0 , teacher_prob: 1 , time:  2  sec \n",
            "Epoch:  72 , Train loss: 0.518747462945826 , Train accuracy: 0 , teacher_prob: 1 , time:  2  sec \n",
            "Epoch:  73 , Train loss: 0.5190430651692783 , Train accuracy: 0 , teacher_prob: 1 , time:  2  sec \n",
            "Epoch:  74 , Train loss: 0.5186791069367352 , Train accuracy: 0 , teacher_prob: 1 , time:  2  sec \n",
            "Epoch:  75 , Train loss: 0.5180589030770695 , Train accuracy: 0 , teacher_prob: 1 , time:  2  sec \n",
            "Epoch:  76 , Train loss: 0.5160929806092206 , Train accuracy: 0 , teacher_prob: 1 , time:  2  sec \n",
            "Epoch:  77 , Train loss: 0.5155684947967529 , Train accuracy: 0 , teacher_prob: 1 , time:  2  sec \n",
            "Epoch:  78 , Train loss: 0.5185980270890629 , Train accuracy: 0 , teacher_prob: 1 , time:  2  sec \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vueXnphmBoiu",
        "colab_type": "text"
      },
      "source": [
        "Above is the main training circle of seq2seq chatbot model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X9-VAQj_etWa",
        "colab_type": "code",
        "outputId": "1a3bee7f-a521-4700-da42-e797b831941e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "\n",
        "print(\"seq2seq is trained\")\n",
        "\n",
        "print(\"training loss: \")\n",
        "plt.plot(train_losses)\n",
        "plt.show()\n",
        "plt.close()\n",
        "print(\"training accuracy: \")\n",
        "plt.plot(train_accuracies)\n",
        "plt.show()\n",
        "plt.close()\n",
        "print(\"argmax recall: \")\n",
        "plt.plot(correction_argmax_recall)\n",
        "plt.show()\n",
        "plt.close()\n",
        "print(\"sample recall: \")\n",
        "plt.plot(correction_sample_recall)\n",
        "plt.show()\n",
        "plt.close()\n",
        "\n",
        "\n",
        "romance_questions = [\"hello , nice to meet you !\",\n",
        "                     \"hi , how are you ?\",\n",
        "                     \"hi pretty one !\",\n",
        "                     \"what is on your mind right now ?\",\n",
        "                     \"what do you want from me ?\",\n",
        "                     \"do you want something from me ?\",\n",
        "                     \"what is your name swettie ?\",\n",
        "                     \"do you like to play ?\",\n",
        "                     \"would you play with me ?\",\n",
        "                     \"am i handsome ?\",\n",
        "                     \"what is on your mind ?\"]\n",
        "\n",
        "\n",
        "\n",
        "def talk_to_me(test_phrases, sampling = False):\n",
        "    converted_test_phrases = []\n",
        "    converted_test_answers = []\n",
        "    test_answers = []\n",
        "\n",
        "    with tf.device(\"cpu:0\"):\n",
        "\n",
        "        for phrase in test_phrases:\n",
        "            phrase = phrase.strip(\" \")\n",
        "            phrase_words = phrase.split(\" \")\n",
        "            skip = False\n",
        "            phrase_words = [\"BEGIN\"] + phrase_words + [\"END\"]\n",
        "            if not skip:\n",
        "                predicted = seq2seq.predict(phrase_words, sampling = sampling)\n",
        "                test_answers.append(predicted)\n",
        "\n",
        "    for i in range(len(test_phrases)):\n",
        "        phrase = test_phrases[i].strip(\" \").split(\" \")\n",
        "\n",
        "        answer = test_answers[i]\n",
        "        converted_answer = \"\"\n",
        "        for word in answer:\n",
        "            converted_answer += word\n",
        "            converted_answer += \" \"\n",
        "\n",
        "        converted_test_answers.append(converted_answer)  \n",
        "\n",
        "    for i in range(len(test_phrases)):\n",
        "        print(test_phrases[i])\n",
        "        print(converted_test_answers[i])\n",
        "        print(\"\\n\")  \n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "seq2seq is trained\n",
            "training loss: \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "training accuracy: \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAD4CAYAAAAHHSreAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "argmax recall: \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD4CAYAAADlwTGnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "sample recall: \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAD4CAYAAADhNOGaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nDIEkNc4QSFLjDIEkNe5/AecL/ch2b2HBAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XMDDmhtZex5R",
        "colab_type": "code",
        "outputId": "3df011e0-3c15-4afb-91c0-529cbc27574e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 798
        }
      },
      "source": [
        "\n",
        "talk_to_me(romance_questions, sampling = True) #old"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "hello , nice to meet you !\n",
            "hi , happy to meet you too ! \n",
            "\n",
            "\n",
            "hi , how are you ?\n",
            "i am fine , thank you ! \n",
            "\n",
            "\n",
            "hi pretty one !\n",
            "hey . \n",
            "\n",
            "\n",
            "what is on your mind right now ?\n",
            "i do not know , dignan . \n",
            "\n",
            "\n",
            "what do you want from me ?\n",
            "your love . \n",
            "\n",
            "\n",
            "do you want something from me ?\n",
            "sure . \n",
            "\n",
            "\n",
            "what is your name swettie ?\n",
            "do not give her your name . \n",
            "\n",
            "\n",
            "do you like to play ?\n",
            "i do not know . \n",
            "\n",
            "\n",
            "would you play with me ?\n",
            "sure . \n",
            "\n",
            "\n",
            "am i handsome ?\n",
            "you can not be out . \n",
            "\n",
            "\n",
            "what is on your mind ?\n",
            "i do not know ... this dna . \n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9wQNI__MLzWT",
        "colab_type": "code",
        "outputId": "20970262-479d-4ebb-a640-7e6875b71286",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "talk_to_me([\"how do you know this ?\"], sampling = False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "how do you know this ?\n",
            "i know . \n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xhnBSIEjAHUZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "import h5py\n",
        "import pickle\n",
        "\n",
        "def download_weights(weights):\n",
        "\n",
        "    weight_file_name = \"weights2_final_v3.\" + \\\n",
        "                        str(MIN_TOKEN_FREQ) + \".\" + \\\n",
        "                         str(MAX_TOKENS_X) + \".\" + \\\n",
        "                         str(MAX_TOKENS_Y) + \".\" + \\\n",
        "                         \"all_except.\" * int(WITH_EXCEPTION) + \\\n",
        "                         GENRES + \".h5\"\n",
        "\n",
        "    with h5py.File(weight_file_name, \"w\") as h5f:\n",
        "        i = 0\n",
        "        for weight in weights:\n",
        "            group = h5f.create_group(str(i))\n",
        "            i += 1\n",
        "            j = 0\n",
        "            for kernel in weight:\n",
        "                group.create_dataset(str(j), data=kernel)\n",
        "                j += 1\n",
        "    h5f.close()\n",
        "    files.download(weight_file_name)\n",
        "\n",
        "with tf.device(\"cpu:0\"):\n",
        "    weights = seq2seq.save()\n",
        "\n",
        "\n",
        "words_file_name = \"words2_final_v3\" + \".\" + str(MIN_TOKEN_FREQ) + \\\n",
        "                     \".\" + str(MAX_TOKENS_X) + \".\" + str(MAX_TOKENS_Y) + \\\n",
        "                      \".\" + \"all_except.\" * int(WITH_EXCEPTION) + \\\n",
        "                      GENRES + \".dict\"\n",
        "\n",
        "with open(words_file_name, \"wb\") as dict_file:\n",
        "    pickle.dump(word_dict, dict_file)\n",
        "\n",
        "download_weights(weights)\n",
        "files.download(words_file_name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lM9YYYtCB8VX",
        "colab_type": "text"
      },
      "source": [
        "And last step is saving weights and words dictionary tokens of trained seq2seq model, code above saves weights in fucntion and two arrays of word indices:\n",
        "first array is array of indices of words that saved seq2seq model is trained on in twitter 50-d embeddings array with 3 adititional words (\"EMPTY\" with index 0, \"START\" with index 1 and \"END\" with index 2), all 3 words are added at the begining of embeddings array.\n",
        "second array is array of word tokens in seq2seq2 model dictionary with which seq2seq model operates, every token at index i in this array corresponds to word index at the same index in first array, so recreated dictionary of saved model will have as keys words from embeddings file with 3 additional words at the begining at indices from first array and as values will have tokens from second array."
      ]
    }
  ]
}